defaults:
  llm: emberfang-llm
  embedding: emberfang-embed
  stt: stt-parakeet-batch
  tts: tts-http
  vector_store: vs-qdrant

models:
  # llama cpp llm, name can be anything
  - name: emberfang-llm
    description: Emberfang One LLM
    model_type: llm
    model_provider: openai
    model_name: gpt-oss-20b-f16
    model_url: http://192.168.1.166:8084/v1
    api_key: "1234"
    model_params:
      temperature: 0.2
      max_tokens: 2000
    model_output: json

  - name: emberfang-embed
    description: Emberfang embeddings (nomic-embed-text)
    model_type: embedding
    model_provider: openai
    model_name: nomic-embed-text-v1.5
    model_url: http://192.168.1.166:8084/v1
    api_key: "1234"
    embedding_dimensions: 768
    model_output: vector

  # Local Ollama LLM (OpenAI-compatible)
  - name: local-llm
    description: Local Ollama LLM
    model_type: llm
    model_provider: ollama
    api_family: openai
    model_name: llama3.1:latest
    model_url: http://localhost:11434/v1
    api_key: ${OPENAI_API_KEY:-ollama}
    model_params:
      temperature: 0.2
      max_tokens: 2000
    model_output: json

  # Local Ollama embedding model (OpenAI-compatible embeddings endpoint)
  - name: local-embed
    description: Local embeddings via Ollama nomic-embed-text
    model_type: embedding
    model_provider: ollama
    api_family: openai
    model_name: nomic-embed-text:latest
    model_url: http://localhost:11434/v1
    api_key: ${OPENAI_API_KEY:-ollama}
    embedding_dimensions: 768
    model_output: vector

  # Hosted OpenAI (optional)
  - name: openai-llm
    description: OpenAI GPT-4o-mini
    model_type: llm
    model_provider: openai
    api_family: openai
    model_name: gpt-4o-mini
    model_url: https://api.openai.com/v1
    api_key: ${OPENAI_API_KEY:-}
    model_params:
      temperature: 0.2
      max_tokens: 2000
    model_output: json

  - name: openai-embed
    description: OpenAI text-embedding-3-small
    model_type: embedding
    model_provider: openai
    api_family: openai
    model_name: text-embedding-3-small
    model_url: https://api.openai.com/v1
    api_key: ${OPENAI_API_KEY:-}
    embedding_dimensions: 1536
    model_output: vector

  # Hosted Groq (OpenAI-compatible chat)
  - name: groq-llm
    description: Groq LLM via OpenAI-compatible API
    model_type: llm
    model_provider: groq
    api_family: openai
    model_name: llama-3.1-70b-versatile
    model_url: https://api.groq.com/openai/v1
    api_key: ${GROQ_API_KEY:-}
    model_params:
      temperature: 0.2
      max_tokens: 2000
    model_output: json

  # Vector store (Qdrant)
  - name: vs-qdrant
    description: Qdrant vector database
    model_type: vector_store
    model_provider: qdrant
    api_family: qdrant
    model_url: http://qdrant:6333
    model_params:
      host: qdrant
      port: 6333
      collection_name: omi_memories

  # STT (Parakeet over HTTP, batch transcription)
  - name: stt-parakeet-batch
    description: Parakeet NeMo ASR (batch)
    model_type: stt
    model_provider: parakeet
    api_family: http
    model_url: http://172.17.0.1:8767
    api_key: ""
    operations:
      stt_transcribe:
        method: POST
        path: /transcribe
        content_type: multipart/form-data
        response:
          type: json
          extract:
            text: text
            words: words
            segments: segments

  # STT (Deepgram over HTTP, config-driven)
  - name: stt-deepgram
    description: Deepgram Nova 3 (batch)
    model_type: stt
    model_provider: deepgram
    api_family: http
    model_url: https://api.deepgram.com/v1
    api_key: ${DEEPGRAM_API_KEY:-}
    operations:
      stt_transcribe:
        method: POST
        path: /listen
        headers:
          Authorization: Token ${DEEPGRAM_API_KEY:-}
          Content-Type: audio/raw
        query:
          model: nova-3
          language: multi
          smart_format: "true"
          punctuate: "true"
          diarize: false
          encoding: linear16
          sample_rate: 16000
          channels: "1"
        response:
          type: json
          extract:
            text: results.channels[0].alternatives[0].transcript
            words: results.channels[0].alternatives[0].words
            segments: results.channels[0].alternatives[0].paragraphs.paragraphs

  # TTS (placeholder; configure to your provider)
  - name: tts-http
    description: Generic JSON TTS endpoint
    model_type: tts
    model_provider: custom
    api_family: http
    model_url: http://localhost:9000
    operations:
      tts_synthesize:
        method: POST
        path: /synthesize
        headers:
          Content-Type: application/json
        response:
          type: json

  # STT streaming (Parakeet via WebSocket; config-driven template)
  - name: stt-parakeet-stream
    description: Parakeet streaming transcription over WebSocket
    model_type: stt_stream
    model_provider: parakeet
    api_family: websocket
    model_url: ws://localhost:9001/stream
    operations:
      start:
        message:
          type: transcribe
          config:
            vad_enabled: true
            vad_silence_ms: 1000
            time_interval_seconds: 30
            return_interim_results: true
            min_audio_seconds: 0.5
      chunk_header:
        message:
          type: audio_chunk
          rate: 16000
          width: 2
          channels: 1
      end:
        message:
          type: stop
      expect:
        interim_type: interim_result
        final_type: final_result
        extract:
          text: text
          words: words
          segments: segments

memory:
  provider: chronicle  # chronicle | openmemory_mcp | mycelia
  timeout_seconds: 1200
  extraction:
    enabled: true
    # Optional custom prompt; if omitted, a built-in default is used
    prompt: |
      Extract important information from this conversation and return a JSON object with an array named "facts". Include personal preferences, plans, names, dates, locations, numbers, and key details. Keep items concise and useful.
  openmemory_mcp:
    server_url: http://localhost:8765
    client_name: chronicle
    user_id: default
    timeout: 30
  mycelia:
    api_url: http://localhost:5173
    timeout: 30
