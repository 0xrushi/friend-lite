"""
Audio file upload and processing controller.

Handles audio file uploads and processes them directly.
Simplified to write files immediately and enqueue transcription.

Also includes audio cropping operations that work with the Conversation model.
"""

import logging
import time
import uuid
from pathlib import Path

from fastapi import UploadFile
from fastapi.responses import JSONResponse

from advanced_omi_backend.utils.audio_utils import (
    AudioValidationError,
    validate_and_prepare_audio,
)
from advanced_omi_backend.utils.audio_chunk_utils import convert_audio_to_chunks
from advanced_omi_backend.models.job import JobPriority
from advanced_omi_backend.models.user import User
from advanced_omi_backend.models.conversation import create_conversation
from advanced_omi_backend.models.conversation import Conversation

logger = logging.getLogger(__name__)
audio_logger = logging.getLogger("audio_processing")


def generate_client_id(user: User, device_name: str) -> str:
    """Generate client ID for uploaded files."""
    logger.debug(f"Generating client ID - user.id={user.id}, type={type(user.id)}")
    user_id_suffix = str(user.id)[-6:]
    return f"{user_id_suffix}-{device_name}"


async def upload_and_process_audio_files(
    user: User,
    files: list[UploadFile],
    device_name: str = "upload",
    auto_generate_client: bool = True,
    folder: str = None,
    source: str = "upload"
) -> dict:
    """
    Upload audio files and process them directly.

    Simplified flow:
    1. Validate and read WAV file
    2. Write audio file and create AudioSession immediately
    3. Enqueue transcription job (same as WebSocket path)

    Args:
        user: Authenticated user
        files: List of uploaded audio files
        device_name: Device identifier
        auto_generate_client: Whether to auto-generate client ID
        folder: Optional subfolder for audio storage (e.g., 'fixtures')
    """
    try:
        if not files:
            return JSONResponse(status_code=400, content={"error": "No files provided"})

        processed_files = []
        client_id = generate_client_id(user, device_name)

        for file_index, file in enumerate(files):
            try:
                # Validate file type (only WAV for now)
                if not file.filename or not file.filename.lower().endswith(".wav"):
                    processed_files.append({
                        "filename": file.filename or "unknown",
                        "status": "error",
                        "error": "Only WAV files are currently supported",
                    })
                    continue

                audio_logger.info(
                    f"üìÅ Uploading file {file_index + 1}/{len(files)}: {file.filename}"
                )

                # Read file content
                content = await file.read()


                # Track external source for deduplication (Google Drive, etc.)
                external_source_id = None
                external_source_type = None
                if source == "gdrive":
                    external_source_id = getattr(file, "file_id", None) or getattr(file, "audio_uuid", None)
                    external_source_type = "gdrive"
                    if not external_source_id:
                        audio_logger.warning(f"Missing file_id for gdrive file: {file.filename}")
                timestamp = int(time.time() * 1000)

                # Validate and prepare audio (read format from WAV file)
                try:
                    audio_data, sample_rate, sample_width, channels, duration = await validate_and_prepare_audio(
                        audio_data=content,
                        expected_sample_rate=16000,  # Expecting 16kHz
                        convert_to_mono=True  # Convert stereo to mono
                    )
                except AudioValidationError as e:
                    processed_files.append({
                        "filename": file.filename,
                        "status": "error",
                        "error": str(e),
                    })
                    continue

                audio_logger.info(
                    f"üìä {file.filename}: {duration:.1f}s ({sample_rate}Hz, {channels}ch, {sample_width} bytes/sample)"
                )

                # Create conversation immediately for uploaded files (conversation_id auto-generated)
                version_id = str(uuid.uuid4())

                # Generate title from filename
                title = file.filename.rsplit('.', 1)[0][:50] if file.filename else "Uploaded Audio"

                conversation = create_conversation(
                    user_id=user.user_id,
                    client_id=client_id,
                    title=title,
                    summary="Processing uploaded audio file...",
                    external_source_id=external_source_id,
                    external_source_type=external_source_type,
                )
                await conversation.insert()
                conversation_id = conversation.conversation_id  # Get the auto-generated ID

                audio_logger.info(f"üìù Created conversation {conversation_id} for uploaded file")

                # Convert audio directly to MongoDB chunks
                try:
                    num_chunks = await convert_audio_to_chunks(
                        conversation_id=conversation_id,
                        audio_data=audio_data,
                        sample_rate=sample_rate,
                        channels=channels,
                        sample_width=sample_width,
                    )
                    audio_logger.info(
                        f"üì¶ Converted uploaded file to {num_chunks} MongoDB chunks "
                        f"(conversation {conversation_id[:12]})"
                    )
                except ValueError as val_error:
                    # Handle validation errors (e.g., file too long)
                    audio_logger.error(f"Audio validation failed: {val_error}")
                    processed_files.append({
                        "filename": file.filename,
                        "status": "error",
                        "error": str(val_error),
                    })
                    # Delete the conversation since it won't have audio chunks
                    await conversation.delete()
                    continue
                except Exception as chunk_error:
                    audio_logger.error(
                        f"Failed to convert uploaded file to chunks: {chunk_error}",
                        exc_info=True
                    )
                    processed_files.append({
                        "filename": file.filename,
                        "status": "error",
                        "error": f"Audio conversion failed: {str(chunk_error)}",
                    })
                    # Delete the conversation since it won't have audio chunks
                    await conversation.delete()
                    continue

                # Enqueue batch transcription job first (file uploads need transcription)
                from advanced_omi_backend.controllers.queue_controller import (
                    start_post_conversation_jobs,
                    transcription_queue,
                    JOB_RESULT_TTL
                )
                from advanced_omi_backend.workers.transcription_jobs import transcribe_full_audio_job

                version_id = str(uuid.uuid4())
                transcribe_job_id = f"transcribe_{conversation_id[:12]}"

                transcription_job = transcription_queue.enqueue(
                    transcribe_full_audio_job,
                    conversation_id,
                    version_id,
                    "batch",  # trigger
                    job_timeout=1800,  # 30 minutes
                    result_ttl=JOB_RESULT_TTL,
                    job_id=transcribe_job_id,
                    description=f"Transcribe uploaded file {conversation_id[:8]}",
                    meta={'conversation_id': conversation_id, 'client_id': client_id}
                )

                audio_logger.info(f"üì• Enqueued transcription job {transcription_job.id} for uploaded file")

                # Enqueue post-conversation processing job chain (depends on transcription)
                job_ids = start_post_conversation_jobs(
                    conversation_id=conversation_id,
                    user_id=user.user_id,
                    transcript_version_id=version_id,  # Pass the version_id from transcription job
                    depends_on_job=transcription_job,  # Wait for transcription to complete
                    client_id=client_id  # Pass client_id for UI tracking
                )

                processed_files.append({
                    "filename": file.filename,
                    "status": "processing",
                    "conversation_id": conversation_id,
                    "transcript_job_id": transcription_job.id,
                    "speaker_job_id": job_ids['speaker_recognition'],
                    "memory_job_id": job_ids['memory'],
                    "duration_seconds": round(duration, 2),
                })

                audio_logger.info(
                    f"‚úÖ Processed {file.filename} ‚Üí conversation {conversation_id}, "
                    f"jobs: {transcription_job.id} ‚Üí {job_ids['speaker_recognition']} ‚Üí {job_ids['memory']}"
                )

            except (OSError, IOError) as e:
                # File I/O errors during audio processing
                audio_logger.exception(f"File I/O error processing {file.filename}")
                processed_files.append({
                    "filename": file.filename or "unknown",
                    "status": "error",
                    "error": str(e),
                })
            except Exception as e:
                # Unexpected errors during file processing
                audio_logger.exception(f"Unexpected error processing file {file.filename}")
                processed_files.append({
                    "filename": file.filename or "unknown",
                    "status": "error",
                    "error": str(e),
                })

        successful_files = [f for f in processed_files if f.get("status") == "processing"]
        failed_files = [f for f in processed_files if f.get("status") == "error"]

        return {
            "message": f"Uploaded and processing {len(successful_files)} file(s)",
            "client_id": client_id,
            "files": processed_files,
            "summary": {
                "total": len(files),
                "processing": len(successful_files),
                "failed": len(failed_files),
            },
        }

    except (OSError, IOError) as e:
        # File system errors during upload handling
        audio_logger.exception("File I/O error in upload_and_process_audio_files")
        return JSONResponse(
            status_code=500, content={"error": f"File upload failed: {str(e)}"}
        )
    except Exception as e:
        # Unexpected errors in upload handler
        audio_logger.exception("Unexpected error in upload_and_process_audio_files")
        return JSONResponse(
            status_code=500, content={"error": f"File upload failed: {str(e)}"}
        )
