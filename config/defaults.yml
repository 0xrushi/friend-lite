# Chronicle Default Configuration
# This file provides sensible defaults for all configuration options.
# User overrides in config.yml take precedence over these defaults.

defaults:
  llm: openai-llm
  embedding: openai-embed
  stt: stt-deepgram
  tts: tts-http
  vector_store: vs-qdrant

models:
  # ===========================
  # LLM Models
  # ===========================
  - name: openai-llm
    description: OpenAI GPT-4o-mini
    model_type: llm
    model_provider: openai
    api_family: openai
    model_name: gpt-4o-mini
    model_url: https://api.openai.com/v1
    api_key: ${OPENAI_API_KEY:-}
    model_params:
      temperature: 0.2
      max_tokens: 2000
    model_output: json

  - name: local-llm
    description: Local Ollama LLM
    model_type: llm
    model_provider: ollama
    api_family: openai
    model_name: llama3.1:latest
    model_url: http://localhost:11434/v1
    api_key: ${OPENAI_API_KEY:-ollama}
    model_params:
      temperature: 0.2
      max_tokens: 2000
    model_output: json

  - name: groq-llm
    description: Groq LLM via OpenAI-compatible API
    model_type: llm
    model_provider: groq
    api_family: openai
    model_name: llama-3.1-70b-versatile
    model_url: https://api.groq.com/openai/v1
    api_key: ${GROQ_API_KEY:-}
    model_params:
      temperature: 0.2
      max_tokens: 2000
    model_output: json

  # ===========================
  # Embedding Models
  # ===========================
  - name: openai-embed
    description: OpenAI text-embedding-3-small
    model_type: embedding
    model_provider: openai
    api_family: openai
    model_name: text-embedding-3-small
    model_url: https://api.openai.com/v1
    api_key: ${OPENAI_API_KEY:-}
    embedding_dimensions: 1536
    model_output: vector

  - name: local-embed
    description: Local embeddings via Ollama nomic-embed-text
    model_type: embedding
    model_provider: ollama
    api_family: openai
    model_name: nomic-embed-text:latest
    model_url: http://localhost:11434/v1
    api_key: ${OPENAI_API_KEY:-ollama}
    embedding_dimensions: 768
    model_output: vector

  # ===========================
  # Speech-to-Text Models
  # ===========================
  - name: stt-deepgram
    description: Deepgram Nova 3 (batch)
    model_type: stt
    model_provider: deepgram
    api_family: http
    model_url: https://api.deepgram.com/v1
    api_key: ${DEEPGRAM_API_KEY:-}
    operations:
      stt_transcribe:
        method: POST
        path: /listen
        headers:
          Authorization: Token ${DEEPGRAM_API_KEY:-}
          Content-Type: audio/raw
        query:
          model: nova-3
          language: multi
          smart_format: 'true'
          punctuate: 'true'
          diarize: 'true'
          encoding: linear16
          sample_rate: 16000
          channels: '1'
        response:
          type: json
          extract:
            text: results.channels[0].alternatives[0].transcript
            words: results.channels[0].alternatives[0].words
            segments: results.channels[0].alternatives[0].paragraphs.paragraphs

  - name: stt-parakeet-batch
    description: Parakeet NeMo ASR (batch)
    model_type: stt
    model_provider: parakeet
    api_family: http
    model_url: http://${PARAKEET_ASR_URL:-172.17.0.1:8767}
    api_key: ''
    operations:
      stt_transcribe:
        method: POST
        path: /transcribe
        content_type: multipart/form-data
        response:
          type: json
          extract:
            text: text
            words: words
            segments: segments

  # ===========================
  # Text-to-Speech Models
  # ===========================
  - name: tts-http
    description: Generic JSON TTS endpoint
    model_type: tts
    model_provider: custom
    api_family: http
    model_url: http://localhost:9000
    operations:
      tts_synthesize:
        method: POST
        path: /synthesize
        headers:
          Content-Type: application/json
        response:
          type: json

  # ===========================
  # Streaming STT Models
  # ===========================
  - name: stt-parakeet-stream
    description: Parakeet streaming transcription over WebSocket
    model_type: stt_stream
    model_provider: parakeet
    api_family: websocket
    model_url: ws://localhost:9001/stream
    operations:
      start:
        message:
          type: transcribe
          config:
            vad_enabled: true
            vad_silence_ms: 1000
            time_interval_seconds: 30
            return_interim_results: true
            min_audio_seconds: 0.5
      chunk_header:
        message:
          type: audio_chunk
          rate: 16000
          width: 2
          channels: 1
      end:
        message:
          type: stop
      expect:
        interim_type: interim_result
        final_type: final_result
        extract:
          text: text
          words: words
          segments: segments

  # ===========================
  # Vector Store
  # ===========================
  - name: vs-qdrant
    description: Qdrant vector database
    model_type: vector_store
    model_provider: qdrant
    api_family: qdrant
    model_url: http://${QDRANT_BASE_URL:-qdrant}:${QDRANT_PORT:-6333}
    model_params:
      host: ${QDRANT_BASE_URL:-qdrant}
      port: ${QDRANT_PORT:-6333}
      collection_name: omi_memories

# ===========================
# Memory Configuration
# ===========================
memory:
  provider: chronicle
  timeout_seconds: 1200
  extraction:
    enabled: true
    prompt: |
      Extract important information from this conversation and return a JSON object with an array named "facts".
      Include personal preferences, plans, names, dates, locations, numbers, and key details.
      Keep items concise and useful.

  # OpenMemory MCP provider settings (used when provider: openmemory_mcp)
  openmemory_mcp:
    server_url: http://localhost:8765
    client_name: chronicle
    user_id: default
    timeout: 30

  # Mycelia provider settings (used when provider: mycelia)
  mycelia:
    api_url: http://localhost:5173
    timeout: 30

  # Obsidian Neo4j provider settings (legacy)
  obsidian:
    enabled: false
    neo4j_host: neo4j-mem0
    timeout: 30

# ===========================
# Speaker Recognition
# ===========================
speaker_recognition:
  # Enable/disable speaker recognition (overrides DISABLE_SPEAKER_RECOGNITION env var)
  enabled: true
  # Service URL (defaults to SPEAKER_SERVICE_URL env var if not specified)
  service_url: null
  # Request timeout in seconds
  timeout: 60

  # Diarization chunking configuration (speaker service self-managed chunking)
  # Maximum audio duration (seconds) for single PyAnnote call
  # Files longer than this will be chunked automatically by the speaker service
  max_diarize_duration: 60
  # Overlap (seconds) between chunks for speaker continuity
  diarize_chunk_overlap: 5.0
  # Backend API URL for fetching audio segments (used by speaker service)
  backend_api_url: http://host.docker.internal:8000

# ===========================
# Chat Configuration
# ===========================
chat:
  system_prompt: |
    You are a helpful AI assistant with access to the user's conversation history and memories.
    Provide clear, concise, and accurate responses based on the context available to you.
