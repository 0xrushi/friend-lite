# ASR Services Configuration
# Copy this file to .env and configure as needed

# =============================================================================
# Provider Selection
# =============================================================================
# Choose one of: faster-whisper, transformers, nemo
ASR_PROVIDER=nemo

# =============================================================================
# Model Configuration
# =============================================================================
# Model identifier (HuggingFace repo or local path)
#
# Faster-Whisper models:
#   - Systran/faster-whisper-large-v3 (Best quality)
#   - Systran/faster-whisper-small (Lightweight)
#   - deepdml/faster-whisper-large-v3-turbo-ct2 (Speed optimized)
#
# Transformers models:
#   - microsoft/VibeVoice-ASR (7B, speaker diarization)
#   - Oriserve/Whisper-Hindi2Hinglish-Prime (Hindi/Hinglish)
#   - openai/whisper-large-v3 (Original Whisper)
#
# NeMo models:
#   - nvidia/parakeet-tdt-0.6b-v3 (Default)
#   - nvidia/canary-1b (Multilingual)
#
ASR_MODEL=nvidia/parakeet-tdt-0.6b-v3

# =============================================================================
# Service Port Configuration
# =============================================================================
ASR_PORT=8767

# =============================================================================
# PyTorch/CUDA Configuration
# =============================================================================
# Options: cu121 (CUDA 12.1), cu126 (CUDA 12.6), cu128 (CUDA 12.8)
PYTORCH_CUDA_VERSION=cu126

# =============================================================================
# Faster-Whisper Provider Settings
# =============================================================================
# Quantization type: float16, int8, float32
COMPUTE_TYPE=float16

# Device: cuda, cpu
DEVICE=cuda

# GPU device index (for multi-GPU systems)
DEVICE_INDEX=0

# Enable Voice Activity Detection filtering
VAD_FILTER=true

# Force language (empty for auto-detect)
# LANGUAGE=en

# =============================================================================
# Transformers Provider Settings
# =============================================================================
# PyTorch data type: float16, float32, bfloat16
TORCH_DTYPE=float16

# Enable Flash Attention 2 (requires compatible GPU)
USE_FLASH_ATTENTION=false

# =============================================================================
# NeMo Provider Settings
# =============================================================================
# NeMo's transcribe() handles long audio natively with timestamps=True.
# No additional configuration needed.
